{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fairness em Usucapião: Rotulagem → Treino (BERTimbau) → Avaliação → Auditoria de Métricas → Adversarial Debiasing\n",
        "Este notebook acopla **fairness** ao pipeline de análise de sentenças (usucapião), usando `magistrado_genero` como atributo sensível (binário: Feminino/Masculino).\n\n",
        "**Referências de fairness**: Equalized Odds / Equal Opportunity (Hardt et al., 2016) e o toolkit **Fairlearn** (Microsoft) para avaliação e mitigação.\n\n",
        "> Equalized Odds/Opportunity: citeturn9search61turn9search64 | Fairlearn & Responsible AI dashboard: citeturn9search44turn9search47 | Adversarial Debiasing: citeturn9search31\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# (Opcional) Instalar dependências (execute se não tiver estes pacotes)\n",
        "# !pip install -q transformers datasets scikit-learn matplotlib fairlearn torch\n",
        "CSV_INPUT = 'resultado_tjma_v2.csv'  # ajuste para o seu caminho\n",
        "CSV_ROTULADO = 'resultado_tjma_rotulado.csv'\n",
        "CSV_MINIMAL = 'dataset_minimal_tjma.csv'\n",
        "MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'  # BERTimbau\n",
        "MODEL_OUT_DIR = 'model_out_tjma'\n",
        "USE_TRANSFORMERS = True  # se quiser desativar, coloque False (usa TF-IDF baseline)\n",
        "SENSITIVE_COL = 'magistrado_genero'\n",
        "SENSITIVE_BIN = ['Feminino','Masculino']  # filtra apenas estes valores para fairness\n",
        "POSITIVE_CLASS = 'procedente'  # para métricas de paridade\n",
        "ADV_LAMBDA = 0.3  # peso da loss adversária\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import re, os, json as pyjson\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (7, 5)\n",
        "\n",
        "# Tenta importar Fairlearn; se não houver, seguimos com cálculo manual\n",
        "try:\n",
        "    from fairlearn.metrics import MetricFrame, selection_rate, true_positive_rate, false_positive_rate\n",
        "    FAIRLEARN_OK = True\n",
        "except Exception as e:\n",
        "    FAIRLEARN_OK = False\n",
        "    print('Fairlearn não disponível, usarei métricas manuais. Erro:', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Carregar CSV e aplicar rotulagem heurística (ternário)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv(CSV_INPUT)\n",
        "len(df), df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Regras heurísticas (iguais às usadas no pipeline anterior)\n",
        "PROCEDENTE = [\n",
        "    r'\\b(julgo\\s+procedente)\\b', r'\\b(proced\\w+)\\b', r'\\b(dou\\s+provimento)\\b', r'\\b(acolho)\\b', r'\\b(condeno)\\b',\n",
        "]\n",
        "IMPROCEDENTE = [\n",
        "    r'\\b(julgo\\s+improcedente)\\b', r'\\b(improced\\w+)\\b', r'\\b(nego\\s+provimento)\\b', r'\\b(rejeito)\\b', r'\\b(desprovido|desprovimento)\\b', r'\\b(improcedentes\\s+os\\s+pedidos)\\b',\n",
        "]\n",
        "NEUTRO = [\n",
        "    r'\\b(julgo\\s+extinto|declaro\\s+extinto|extin\\w+\\s+do\\s+processo)\\b',\n",
        "    r'\\b(sem\\s+resolu\\w+\\s+do\\s+m\\w+rito|art\\.?\\s*485)\\b',\n",
        "    r'\\b(homologo\\s+acordo|homologa\\w+|homologo\\s+desist\\w+)\\b',\n",
        "    r'\\b(perda\\s+do\\s+objeto|car\\w+ncia\\s+de\\s+a\\w+\\w+o)\\b',\n",
        "    r'\\b(ilegitimidade|incompet\\w+ncia|litispend\\w+ncia)\\b',\n",
        "    r'\\b(indeferimento\\s+da\\s+peti\\w+\\s+inicial|indefiro\\s+a\\s+inicial|rejeito\\s+a\\s+inicial)\\b',\n",
        "]\n",
        "MERITO = [r'\\b(resolu\\w+\\s+do\\s+m\\w+rito)\\b', r'\\b(art\\.?\\s*487)\\b']\n",
        "SEM_MERITO = [r'\\b(sem\\s+resolu\\w+\\s+do\\s+m\\w+rito)\\b', r'\\b(art\\.?\\s*485)\\b']\n",
        "\n",
        "def norm(s):\n",
        "    if not isinstance(s, str): return ''\n",
        "    s = s.strip()\n",
        "    return re.sub(r'\\s+', ' ', s)\n",
        "\n",
        "def find_first_match(text, patterns):\n",
        "    for rx in patterns:\n",
        "        if re.search(rx, text, flags=re.IGNORECASE):\n",
        "            return rx\n",
        "    return None\n",
        "\n",
        "def rotular_decisao(text):\n",
        "    t = norm(text)\n",
        "    ev = find_first_match(t, PROCEDENTE)\n",
        "    if ev:\n",
        "        tipo = 'merito' if find_first_match(t, MERITO) else ('sem_merito' if find_first_match(t, SEM_MERITO) else 'merito')\n",
        "        return ('procedente', ev, tipo, 0.95)\n",
        "    ev = find_first_match(t, IMPROCEDENTE)\n",
        "    if ev:\n",
        "        tipo = 'merito' if find_first_match(t, MERITO) else ('sem_merito' if find_first_match(t, SEM_MERITO) else 'merito')\n",
        "        return ('improcedente', ev, tipo, 0.95)\n",
        "    ev = find_first_match(t, NEUTRO)\n",
        "    if ev:\n",
        "        return ('neutro', ev, 'sem_merito', 0.90)\n",
        "    if find_first_match(t, MERITO):\n",
        "        return ('neutro', None, 'merito', 0.60)\n",
        "    if find_first_match(t, SEM_MERITO):\n",
        "        return ('neutro', None, 'sem_merito', 0.70)\n",
        "    return ('neutro', None, None, 0.50)\n",
        "\n",
        "out = df.copy()\n",
        "res = out['decisao'].apply(rotular_decisao)\n",
        "out['sentimento'] = res.apply(lambda x: x[0])\n",
        "out['evidencia'] = res.apply(lambda x: x[1])\n",
        "out['tipo_resultado'] = res.apply(lambda x: x[2])\n",
        "out['confianca'] = res.apply(lambda x: x[3])\n",
        "print('Distribuição de rótulos:')\n",
        "print(out['sentimento'].value_counts())\n",
        "out.to_csv(CSV_ROTULADO, index=False)\n",
        "minimal = out[['decisao','sentimento',SENSITIVE_COL]].rename(columns={'decisao':'text','sentimento':'label'})\n",
        "minimal['text'] = minimal['text'].fillna('').astype(str).str.strip()\n",
        "minimal = minimal[minimal['text'].str.len() > 3]\n",
        "minimal.to_csv(CSV_MINIMAL, index=False)\n",
        "CSV_ROTULADO, CSV_MINIMAL, len(minimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Treino (baseline) e avaliação macro — BERTimbau (ou TF‑IDF fallback)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "label2id = {'procedente':0, 'improcedente':1, 'neutro':2}\n",
        "id2label = {v:k for k,v in label2id.items()}\n",
        "minimal['label_id'] = minimal['label'].map(label2id)\n",
        "minimal = minimal.dropna(subset=['label_id'])\n",
        "# filtra apenas F/M para fairness\n",
        "minimal = minimal[minimal[SENSITIVE_COL].isin(SENSITIVE_BIN)]\n",
        "train_df, test_df = train_test_split(minimal, test_size=0.2, random_state=42, stratify=minimal['label_id'])\n",
        "len(train_df), len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pred_base = None\n",
        "if USE_TRANSFORMERS:\n",
        "    from transformers import (AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments)\n",
        "    from transformers import DataCollatorWithPadding\n",
        "    from datasets import Dataset, DatasetDict\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    train_ds = Dataset.from_pandas(train_df[['text','label_id']].rename(columns={'label_id':'labels'}))\n",
        "    test_ds  = Dataset.from_pandas(test_df[['text','label_id']].rename(columns={'label_id':'labels'}))\n",
        "    ds = DatasetDict({'train':train_ds, 'test':test_ds})\n",
        "    def tok(batch):\n",
        "        return tokenizer(batch['text'], truncation=True, max_length=512)\n",
        "    ds_tok = ds.map(tok, batched=True)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3, id2label=id2label, label2id=label2id)\n",
        "    collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "    import numpy as np\n",
        "    def compute_metrics(eval_pred):\n",
        "        logits, labels = eval_pred\n",
        "        preds = np.argmax(logits, axis=-1)\n",
        "        return {\n",
        "            'accuracy': accuracy_score(labels, preds),\n",
        "            'precision_macro': precision_score(labels, preds, average='macro', zero_division=0),\n",
        "            'recall_macro': recall_score(labels, preds, average='macro', zero_division=0),\n",
        "            'f1_macro': f1_score(labels, preds, average='macro', zero_division=0),\n",
        "        }\n",
        "    args = TrainingArguments(output_dir=MODEL_OUT_DIR, per_device_train_batch_size=16, per_device_eval_batch_size=32, num_train_epochs=2, learning_rate=2e-5, evaluation_strategy='epoch', save_strategy='epoch', report_to='none', load_best_model_at_end=True, metric_for_best_model='f1_macro')\n",
        "    trainer = Trainer(model=model, args=args, train_dataset=ds_tok['train'], eval_dataset=ds_tok['test'], tokenizer=tokenizer, data_collator=collator, compute_metrics=compute_metrics)\n",
        "    trainer.train()\n",
        "    eval_metrics = trainer.evaluate()\n",
        "    preds = trainer.predict(ds_tok['test'])\n",
        "    y_true = np.array(preds.label_ids)\n",
        "    y_pred = np.argmax(preds.predictions, axis=-1)\n",
        "else:\n",
        "    # Fallback rápido: TF-IDF + LogisticRegression\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    vec = TfidfVectorizer(max_features=30000, ngram_range=(1,2))\n",
        "    Xtr = vec.fit_transform(train_df['text'])\n",
        "    Xte = vec.transform(test_df['text'])\n",
        "    clf = LogisticRegression(max_iter=200)\n",
        "    clf.fit(Xtr, train_df['label_id'])\n",
        "    y_pred = clf.predict(Xte)\n",
        "    y_true = np.array(test_df['label_id'])\n",
        "    eval_metrics = {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
        "        'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
        "        'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
        "    }\n",
        "eval_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Auditoria de fairness (grupo = `magistrado_genero`) — Observado vs. Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Junta rótulos e grupos no teste\n",
        "test_eval = test_df.copy()\n",
        "test_eval['y_true'] = y_true\n",
        "test_eval['y_pred'] = y_pred\n",
        "# Define 'positivo' como classe 0 (procedente)\n",
        "POS_ID = label2id[POSITIVE_CLASS]\n",
        "\n",
        "def rate_positive(y):\n",
        "    return np.mean(np.array(y)==POS_ID)\n",
        "\n",
        "def group_rates(df_in, col=SENSITIVE_COL):\n",
        "    res = {}\n",
        "    for g in SENSITIVE_BIN:\n",
        "        dfg = df_in[df_in[col]==g]\n",
        "        res[g] = {\n",
        "            'selection_rate_true': rate_positive(dfg['y_true']),\n",
        "            'selection_rate_pred': rate_positive(dfg['y_pred']),\n",
        "        }\n",
        "        # TPR/FPR por grupo no modelo\n",
        "        yt = (dfg['y_true'].values==POS_ID).astype(int)\n",
        "        yp = (dfg['y_pred'].values==POS_ID).astype(int)\n",
        "        # evitar divisão por zero\n",
        "        TPR = (np.sum((yp==1)&(yt==1))/max(np.sum(yt==1),1))\n",
        "        FPR = (np.sum((yp==1)&(yt==0))/max(np.sum(yt==0),1))\n",
        "        res[g]['TPR'] = TPR\n",
        "        res[g]['FPR'] = FPR\n",
        "    return res\n",
        "\n",
        "rates = group_rates(test_eval)\n",
        "rates\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Diferenças de disparidade (diferença absoluto entre grupos)\n",
        "def disparity_diffs(rates):\n",
        "    g0, g1 = SENSITIVE_BIN\n",
        "    diffs = {\n",
        "        'demographic_parity_true_diff': abs(rates[g0]['selection_rate_true'] - rates[g1]['selection_rate_true']),\n",
        "        'demographic_parity_pred_diff': abs(rates[g0]['selection_rate_pred'] - rates[g1]['selection_rate_pred']),\n",
        "        'equal_opportunity_diff': abs(rates[g0]['TPR'] - rates[g1]['TPR']),\n",
        "        'equalized_odds_FPR_diff': abs(rates[g0]['FPR'] - rates[g1]['FPR']),\n",
        "    }\n",
        "    return diffs\n",
        "\n",
        "diffs_base = disparity_diffs(rates)\n",
        "diffs_base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (Opcional) Usar Fairlearn se disponível (MetricFrame)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if FAIRLEARN_OK:\n",
        "    yt = (test_eval['y_true'].values==POS_ID).astype(int)\n",
        "    yp = (test_eval['y_pred'].values==POS_ID).astype(int)\n",
        "    sf = test_eval[SENSITIVE_COL].values\n",
        "    mf = MetricFrame(metrics={\n",
        "        'selection_rate': selection_rate,\n",
        "        'TPR': true_positive_rate,\n",
        "        'FPR': false_positive_rate,\n",
        "    }, y_true=yt, y_pred=yp, sensitive_features=sf)\n",
        "    print(mf.by_group)\n",
        "    print('Max disparity (selection):', mf.difference()['selection_rate'])\n",
        "else:\n",
        "    print('Fairlearn indisponível — métricas já calculadas manualmente acima.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Visualizações rápidas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Barras de TPR/FPR por grupo\n",
        "g0, g1 = SENSITIVE_BIN\n",
        "labels = ['TPR','FPR']\n",
        "vals0 = [rates[g0]['TPR'], rates[g0]['FPR']]\n",
        "vals1 = [rates[g1]['TPR'], rates[g1]['FPR']]\n",
        "x = np.arange(len(labels))\n",
        "w = 0.35\n",
        "plt.bar(x-w/2, vals0, width=w, label=g0)\n",
        "plt.bar(x+w/2, vals1, width=w, label=g1)\n",
        "plt.xticks(x, labels)\n",
        "plt.ylim(0,1)\n",
        "plt.title('TPR/FPR por gênero (modelo base)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Protótipo de Adversarial Debiasing (BERT + Gradient Reversal)\n",
        "Treinamos um encoder (BERTimbau) com duas cabeças: (i) **classificação** do resultado e (ii) **adversária** para prever o gênero do julgador; a loss total é `L_cls - λ * L_adv` (λ = `ADV_LAMBDA`), forçando o encoder a **não carregar informação** sobre o atributo sensível. citeturn9search31"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
        "\n",
        "class GRL(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, lambda_):\n",
        "        ctx.lambda_ = lambda_\n",
        "        return x.view_as(x)\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return -ctx.lambda_ * grad_output, None\n",
        "\n",
        "class AdvModel(nn.Module):\n",
        "    def __init__(self, model_name, num_labels=3):\n",
        "        super().__init__()\n",
        "        from transformers import AutoModel\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        hidden = self.encoder.config.hidden_size\n",
        "        self.classifier = nn.Linear(hidden, num_labels)\n",
        "        self.adv_head = nn.Linear(hidden, 2)  # gênero binário\n",
        "    def forward(self, **inputs):\n",
        "        out = self.encoder(**inputs)\n",
        "        h = out.last_hidden_state[:,0,:]  # CLS\n",
        "        logits_cls = self.classifier(h)\n",
        "        return logits_cls, h\n",
        "    def adv(self, h, lambda_):\n",
        "        h_grl = GRL.apply(h, lambda_)\n",
        "        logits_adv = self.adv_head(h_grl)\n",
        "        return logits_adv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dataset torch\n",
        "class TextDataset(TorchDataset):\n",
        "    def __init__(self, df, tokenizer, max_len=256):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        enc = self.tok(row['text'], truncation=True, max_length=self.max_len, padding='max_length', return_tensors='pt')\n",
        "        item = {k:v.squeeze(0) for k,v in enc.items()}\n",
        "        item['labels'] = torch.tensor(int(row['label_id']))\n",
        "        # gênero binário: Feminino=0, Masculino=1\n",
        "        g = 0 if row[SENSITIVE_COL]=='Feminino' else 1\n",
        "        item['gender'] = torch.tensor(g)\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if USE_TRANSFORMERS:\n",
        "    from transformers import AutoTokenizer\n",
        "    tok2 = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    tr_ds = TextDataset(train_df[['text','label_id',SENSITIVE_COL]], tok2)\n",
        "    te_ds = TextDataset(test_df[['text','label_id',SENSITIVE_COL]], tok2)\n",
        "    tr_dl = DataLoader(tr_ds, batch_size=16, shuffle=True)\n",
        "    te_dl = DataLoader(te_ds, batch_size=32)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    adv_model = AdvModel(MODEL_NAME).to(device)\n",
        "    opt = torch.optim.AdamW(adv_model.parameters(), lr=2e-5)\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    # Treino curto (1 época) só para demonstrar\n",
        "    adv_model.train()\n",
        "    for epoch in range(1):\n",
        "        for batch in tr_dl:\n",
        "            inputs = {k:batch[k].to(device) for k in ['input_ids','attention_mask']}\n",
        "            y = batch['labels'].to(device)\n",
        "            g = batch['gender'].to(device)\n",
        "            logits_cls, h = adv_model(**inputs)\n",
        "            loss_cls = ce(logits_cls, y)\n",
        "            logits_adv = adv_model.adv(h, ADV_LAMBDA)\n",
        "            loss_adv = ce(logits_adv, g)\n",
        "            loss = loss_cls - ADV_LAMBDA*loss_adv\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "    # Avaliação\n",
        "    adv_model.eval()\n",
        "    y_true2, y_pred2, groups2 = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in te_dl:\n",
        "            inputs = {k:batch[k].to(device) for k in ['input_ids','attention_mask']}\n",
        "            logits_cls, _ = adv_model(**inputs)\n",
        "            pred = torch.argmax(logits_cls, dim=-1).cpu().numpy()\n",
        "            y_pred2.extend(list(pred))\n",
        "            y_true2.extend(list(batch['labels'].numpy()))\n",
        "            groups2.extend(list(batch['gender'].numpy()))\n",
        "    y_true2 = np.array(y_true2); y_pred2 = np.array(y_pred2); groups2 = np.array(groups2)\n",
        "    # Monta DF para métricas\n",
        "    test_eval_adv = test_df.copy()\n",
        "    test_eval_adv['y_true'] = y_true2\n",
        "    test_eval_adv['y_pred'] = y_pred2\n",
        "    test_eval_adv['bin_gender'] = np.where(test_eval_adv[SENSITIVE_COL]=='Feminino','Feminino','Masculino')\n",
        "    # Calcula disparidades\n",
        "    def compute_rates_df(df_in):\n",
        "        res = {}\n",
        "        for g in SENSITIVE_BIN:\n",
        "            dfg = df_in[df_in['bin_gender']==g]\n",
        "            sel_pred = np.mean(dfg['y_pred'].values==POS_ID)\n",
        "            yt = (dfg['y_true'].values==POS_ID).astype(int); yp = (dfg['y_pred'].values==POS_ID).astype(int)\n",
        "            TPR = (np.sum((yp==1)&(yt==1))/max(np.sum(yt==1),1))\n",
        "            FPR = (np.sum((yp==1)&(yt==0))/max(np.sum(yt==0),1))\n",
        "            res[g] = {'selection_rate_pred': sel_pred, 'TPR': TPR, 'FPR': FPR}\n",
        "        return res\n",
        "    rates_adv = compute_rates_df(test_eval_adv)\n",
        "    diffs_adv = {\n",
        "        'demographic_parity_pred_diff': abs(rates_adv[SENSITIVE_BIN[0]]['selection_rate_pred'] - rates_adv[SENSITIVE_BIN[1]]['selection_rate_pred']),\n",
        "        'equal_opportunity_diff': abs(rates_adv[SENSITIVE_BIN[0]]['TPR'] - rates_adv[SENSITIVE_BIN[1]]['TPR']),\n",
        "        'equalized_odds_FPR_diff': abs(rates_adv[SENSITIVE_BIN[0]]['FPR'] - rates_adv[SENSITIVE_BIN[1]]['FPR']),\n",
        "    }\n",
        "    rates_adv, diffs_adv\n",
        "else:\n",
        "    print('Adversarial requer Transformers; ative USE_TRANSFORMERS=True e instale dependências.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Comparação de disparidades: Base vs. Adversarial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if USE_TRANSFORMERS:\n",
        "    print('Base:', diffs_base)\n",
        "    print('Adv :', diffs_adv)\n",
        "    # Barras de comparação (paridade predita)\n",
        "    dp_base = diffs_base['demographic_parity_pred_diff']\n",
        "    eo_base = diffs_base['equal_opportunity_diff']\n",
        "    eod_base = diffs_base['equalized_odds_FPR_diff']\n",
        "    dp_adv = diffs_adv['demographic_parity_pred_diff']\n",
        "    eo_adv = diffs_adv['equal_opportunity_diff']\n",
        "    eod_adv = diffs_adv['equalized_odds_FPR_diff']\n",
        "    lbls = ['Parity diff','EO diff (TPR)','EOdds diff (FPR)']\n",
        "    base_vals = [dp_base, eo_base, eod_base]\n",
        "    adv_vals = [dp_adv, eo_adv, eod_adv]\n",
        "    x = np.arange(len(lbls)); w=0.35\n",
        "    plt.bar(x-w/2, base_vals, width=w, label='Base')\n",
        "    plt.bar(x+w/2, adv_vals, width=w, label='Adversarial')\n",
        "    plt.xticks(x, lbls); plt.title('Disparidades por gênero — Base vs. Adversarial')\n",
        "    plt.legend(); plt.show()\n",
        "else:\n",
        "    print('Sem Transformers, comparação adversarial não foi executada.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Salvar relatório de fairness\n",
        "Salvamos métricas principais em `fairness_report.json` para posterior uso no dashboard/RAI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "report = {\n",
        "  'base': diffs_base,\n",
        "}\n",
        "if USE_TRANSFORMERS:\n",
        "    report['adversarial'] = diffs_adv\n",
        "with open('fairness_report.json','w',encoding='utf-8') as f:\n",
        "    pyjson.dump(report, f, ensure_ascii=False, indent=2)\n",
        "'fairness_report.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Observações finais\n",
        "- **Métricas**: Equalized Odds/Opportunity focam em **taxas de erro por grupo**; Paridade demográfica mede **taxas de positivos** (procedente) por grupo. citeturn9search61turn9search48\n",
        "- **Fairness é sociotécnico**: pode haver trade-offs entre métricas e acurácia; contextualize no domínio jurídico (processo, provas, tipologia de casos). citeturn9search47\n",
        "- **Adversarial debiasing** é uma abordagem prática para reduzir sinal do atributo sensível nas representações sem grande perda de performance. citeturn9search31\n"
      ]
    }
  ]
}